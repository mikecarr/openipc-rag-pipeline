
App Url: http://localhost:5173


## Inject Data
python ingest.py                             
--- Starting Knowledge Base Ingestion ---


https://ollama.com/library/llama3/

brew services start ollama

# download could take a while
ollama run llama3:8b-instruct-q4_K_M